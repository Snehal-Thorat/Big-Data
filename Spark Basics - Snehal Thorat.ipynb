{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7- Snehal Thorat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (30 points)\n",
    "1. Create Spark session as we did in the class. Make sure you enable Hive support.\n",
    "2. Load all files from \"data\\retail-data\\by-day\" into a single Spark DataFrame. There should be 300+ files in\n",
    "the folder.\n",
    "3. Print Schema of the DF created in 1.1\n",
    "4. Create SQL temp table to be used in Spark SQL for the current session. Name table \"RetailData\"\n",
    "5. Display list of Hive Tables, permanent and temporary in the \"default\" schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import instr,col\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"assign7\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.61.131:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>assign7</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f471b99c2e8>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(\"/mnt/hgfs/Shared_folder/Spark-The-Definitive-Guide-master/data/retail-data/by-day/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"RetailData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+\n",
      "|database|  tableName|isTemporary|\n",
      "+--------+-----------+-----------+\n",
      "| default|   business|      false|\n",
      "| default|business_pq|      false|\n",
      "| default|  people_pq|      false|\n",
      "| default|     review|      false|\n",
      "| default|  review_pq|      false|\n",
      "| default|  sample_07|      false|\n",
      "| default|  sample_08|      false|\n",
      "| default|     u_data|      false|\n",
      "| default|  u_data_pq|      false|\n",
      "| default|     u_item|      false|\n",
      "| default|  u_item_pq|      false|\n",
      "| default|     u_user|      false|\n",
      "| default|  u_user_pq|      false|\n",
      "| default|      users|      false|\n",
      "| default|   users_pq|      false|\n",
      "|        | retaildata|       true|\n",
      "+--------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (30 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cache the DF so that it will reside in memory after first \"action\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: timestamp, UnitPrice: double, CustomerID: double, Country: string]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Perform count() function on the DataFrame to cache the DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541909"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Use limit function to display first five records using both SQL and DF API. Full content of each column\n",
    "should be displayed, use proper parameter to show() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM retaildata limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "|   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (60 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Spark API and Spar SQL (two different commands) to find how many records are present in the DF loaded\n",
    "in \"1\" for every year-month combination. Sort by year-month in default sort order.\n",
    "1. Hint 1 - use concat, year, month functions for DF API\n",
    "2. Hint 2 - use date_format for Spark SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------------------------------+--------+\n",
      "|year(CAST(InvoiceDate AS DATE))|month(CAST(InvoiceDate AS DATE))|count(1)|\n",
      "+-------------------------------+--------------------------------+--------+\n",
      "|                           2010|                              12|   42481|\n",
      "|                           2011|                               1|   35147|\n",
      "|                           2011|                               2|   27707|\n",
      "|                           2011|                               3|   36748|\n",
      "|                           2011|                               4|   29916|\n",
      "|                           2011|                               5|   37030|\n",
      "|                           2011|                               6|   36874|\n",
      "|                           2011|                               7|   39518|\n",
      "|                           2011|                               8|   35284|\n",
      "|                           2011|                               9|   50226|\n",
      "|                           2011|                              10|   60742|\n",
      "|                           2011|                              11|   84711|\n",
      "|                           2011|                              12|   25525|\n",
      "+-------------------------------+--------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT YEAR(InvoiceDate), MONTH(InvoiceDate),COUNT(*) FROM retaildata GROUP BY YEAR(InvoiceDate), MONTH(InvoiceDate) ORDER BY YEAR(InvoiceDate), MONTH(InvoiceDate)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|Year|Month|count|\n",
      "+----+-----+-----+\n",
      "|2010|   12|42481|\n",
      "|2011|   01|35147|\n",
      "|2011|   02|27707|\n",
      "|2011|   03|36748|\n",
      "|2011|   04|29916|\n",
      "|2011|   05|37030|\n",
      "|2011|   06|36874|\n",
      "|2011|   07|39518|\n",
      "|2011|   08|35284|\n",
      "|2011|   09|50226|\n",
      "|2011|   10|60742|\n",
      "|2011|   11|84711|\n",
      "|2011|   12|25525|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_year_month = df.withColumn('Year', F.split(df.InvoiceDate, '-')[0]).withColumn('Month', F.split(df.InvoiceDate, '-')[1])\n",
    "df_year_month.groupBy(\"Year\",\"Month\").count().orderBy(\"Year\",\"Month\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (80 points) - Spark API (not SQL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) How many records have Null in field \"Description\"?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1454"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"description\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Create new DF and populate field \"Description\" with 'NULL-STR string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First let's clean up the DF: Replace two Spaces with one Space\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "df = df.withColumn('Clean_Desc',regexp_replace(col(\"Description\"), \"  \", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+-------------------+---------+----------+--------------+------------------+\n",
      "|InvoiceNo|StockCode|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|        Clean_Desc|\n",
      "+---------+---------+--------+-------------------+---------+----------+--------------+------------------+\n",
      "|   580538|    23084|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|RABBIT NIGHT LIGHT|\n",
      "+---------+---------+--------+-------------------+---------+----------+--------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, lit\n",
    "df1 = df.withColumn(\"Clean_Desc\",coalesce(col(\"Description\"),lit(\"NULL-STR\")))\n",
    "df1 = df1.drop('Description')\n",
    "df1.show(1)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Create new Boolean column for each item in the following list:\n",
    "['lunch','dinner','supper','breakfast']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(InvoiceNo='580538', StockCode='23084', Quantity=48, InvoiceDate=datetime.datetime(2011, 12, 5, 8, 38), UnitPrice=1.79, CustomerID=14075.0, Country='United Kingdom', Clean_Desc='RABBIT NIGHT LIGHT', is_Lunch=False, is_dinner=False, is_supper=False, is_breakfast=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#is_lunch|is_dinner|is_supper|is_breakfast\n",
    "\n",
    "df4 = df1.withColumn('is_Lunch',df1.Clean_Desc.contains('LUNCH')).withColumn('is_dinner',df1.Clean_Desc.contains('DINNER')).withColumn('is_supper',df1.Clean_Desc.contains('SUPPER')).withColumn('is_breakfast',df1.Clean_Desc.contains('BREAKFAST'))\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InvoiceNo',\n",
       " 'StockCode',\n",
       " 'Quantity',\n",
       " 'InvoiceDate',\n",
       " 'UnitPrice',\n",
       " 'CustomerID',\n",
       " 'Country',\n",
       " 'Clean_Desc',\n",
       " 'is_Lunch',\n",
       " 'is_dinner',\n",
       " 'is_supper',\n",
       " 'is_breakfast']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Populate the column as in the example below, and output first 50 records that had any of the items in\n",
    "the item list matched to the content of the column \"Description\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+-------------------+---------+----------+--------------+--------------------+--------+---------+---------+------------+\n",
      "|InvoiceNo|StockCode|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|          Clean_Desc|is_Lunch|is_dinner|is_supper|is_breakfast|\n",
      "+---------+---------+--------+-------------------+---------+----------+--------------+--------------------+--------+---------+---------+------------+\n",
      "|   580540|    22109|       4|2011-12-05 08:49:00|     3.75|   13417.0|United Kingdom|FULL ENGLISH BREA...|   false|    false|    false|        true|\n",
      "|   580545|    23209|      10|2011-12-05 09:16:00|     1.65|   12782.0|      Portugal|LUNCH BAG VINTAGE...|    true|    false|    false|       false|\n",
      "|   580545|    23583|      10|2011-12-05 09:16:00|     1.65|   12782.0|      Portugal|LUNCH BAG PAISLEY...|    true|    false|    false|       false|\n",
      "|   580595|    22383|      10|2011-12-05 10:38:00|     1.65|   14194.0|United Kingdom|LUNCH BAG SUKI DE...|    true|    false|    false|       false|\n",
      "|   580608|    22631|      12|2011-12-05 11:39:00|     1.95|   16811.0|United Kingdom|CIRCUS PARADE LUN...|    true|    false|    false|       false|\n",
      "|   580608|    20726|      10|2011-12-05 11:39:00|     1.65|   16811.0|United Kingdom|  LUNCH BAG WOODLAND|    true|    false|    false|       false|\n",
      "|   580608|    22629|      12|2011-12-05 11:39:00|     1.95|   16811.0|United Kingdom| SPACEBOY LUNCH BOX |    true|    false|    false|       false|\n",
      "|   580608|    22630|      12|2011-12-05 11:39:00|     1.95|   16811.0|United Kingdom|DOLLY GIRL LUNCH BOX|    true|    false|    false|       false|\n",
      "|   580610|    20726|       4|2011-12-05 11:48:00|     4.13|      null|United Kingdom|  LUNCH BAG WOODLAND|    true|    false|    false|       false|\n",
      "|   580610|    20728|       1|2011-12-05 11:48:00|     4.13|      null|United Kingdom| LUNCH BAG CARS BLUE|    true|    false|    false|       false|\n",
      "|   580610|    21558|       2|2011-12-05 11:48:00|     4.96|      null|United Kingdom|SKULL LUNCH BOX W...|    true|    false|    false|       false|\n",
      "|   580610|    21559|       1|2011-12-05 11:48:00|     4.96|      null|United Kingdom|STRAWBERRY LUNCH ...|    true|    false|    false|       false|\n",
      "|   580610|    21561|       1|2011-12-05 11:48:00|     4.96|      null|United Kingdom|DINOSAUR LUNCH BO...|    true|    false|    false|       false|\n",
      "|   580610|    22352|       5|2011-12-05 11:48:00|     4.13|      null|United Kingdom|LUNCH BOX WITH CU...|    true|    false|    false|       false|\n",
      "|   580610|    22384|       1|2011-12-05 11:48:00|     4.96|      null|United Kingdom|LUNCH BAG PINK PO...|    true|    false|    false|       false|\n",
      "|   580610|    22472|       1|2011-12-05 11:48:00|    10.79|      null|United Kingdom|TV DINNER TRAY DO...|   false|     true|    false|       false|\n",
      "|   580610|    22474|       2|2011-12-05 11:48:00|    10.79|      null|United Kingdom|SPACEBOY TV DINNE...|   false|     true|    false|       false|\n",
      "|   580610|    22630|       1|2011-12-05 11:48:00|     2.46|      null|United Kingdom|DOLLY GIRL LUNCH BOX|    true|    false|    false|       false|\n",
      "|   580610|   72801d|       1|2011-12-05 11:48:00|     2.46|      null|United Kingdom|4 SKY BLUE DINNER...|   false|     true|    false|       false|\n",
      "|   580611|    20727|       1|2011-12-05 11:49:00|     1.65|   12748.0|United Kingdom|LUNCH BAG  BLACK ...|    true|    false|    false|       false|\n",
      "|   580611|    20727|       1|2011-12-05 11:49:00|     1.65|   12748.0|United Kingdom|LUNCH BAG  BLACK ...|    true|    false|    false|       false|\n",
      "|   580611|    23206|       2|2011-12-05 11:49:00|     1.65|   12748.0|United Kingdom|LUNCH BAG APPLE D...|    true|    false|    false|       false|\n",
      "|   580612|    22471|       1|2011-12-05 11:58:00|    10.79|      null|United Kingdom|TV DINNER TRAY AI...|   false|     true|    false|       false|\n",
      "|   580612|    22474|       2|2011-12-05 11:58:00|    10.79|      null|United Kingdom|SPACEBOY TV DINNE...|   false|     true|    false|       false|\n",
      "|   580612|    22475|       1|2011-12-05 11:58:00|    10.79|      null|United Kingdom|SKULL DESIGN TV D...|   false|     true|    false|       false|\n",
      "|   580612|    22629|       2|2011-12-05 11:58:00|     2.46|      null|United Kingdom| SPACEBOY LUNCH BOX |    true|    false|    false|       false|\n",
      "|   580612|    22630|       4|2011-12-05 11:58:00|     2.46|      null|United Kingdom|DOLLY GIRL LUNCH BOX|    true|    false|    false|       false|\n",
      "|   580612|   72801d|       1|2011-12-05 11:58:00|     2.46|      null|United Kingdom|4 SKY BLUE DINNER...|   false|     true|    false|       false|\n",
      "|   580612|    20726|       4|2011-12-05 11:58:00|     4.13|      null|United Kingdom|  LUNCH BAG WOODLAND|    true|    false|    false|       false|\n",
      "|   580612|    20728|       3|2011-12-05 11:58:00|     4.13|      null|United Kingdom| LUNCH BAG CARS BLUE|    true|    false|    false|       false|\n",
      "|   580612|    21558|       1|2011-12-05 11:58:00|     4.96|      null|United Kingdom|SKULL LUNCH BOX W...|    true|    false|    false|       false|\n",
      "|   580612|    21559|       2|2011-12-05 11:58:00|     4.96|      null|United Kingdom|STRAWBERRY LUNCH ...|    true|    false|    false|       false|\n",
      "|   580612|    22352|       1|2011-12-05 11:58:00|     4.13|      null|United Kingdom|LUNCH BOX WITH CU...|    true|    false|    false|       false|\n",
      "|   580612|    22384|       1|2011-12-05 11:58:00|     4.96|      null|United Kingdom|LUNCH BAG PINK PO...|    true|    false|    false|       false|\n",
      "|   580615|    23681|      10|2011-12-05 12:05:00|     1.65|   16873.0|United Kingdom|LUNCH BAG RED VIN...|    true|    false|    false|       false|\n",
      "|   580615|    22109|       8|2011-12-05 12:05:00|     3.75|   16873.0|United Kingdom|FULL ENGLISH BREA...|   false|    false|    false|        true|\n",
      "|   580619|    22471|       1|2011-12-05 12:08:00|     1.95|   15053.0|United Kingdom|TV DINNER TRAY AI...|   false|     true|    false|       false|\n",
      "|   580631|    22634|       2|2011-12-05 12:13:00|     9.95|   16682.0|United Kingdom|CHILDS BREAKFAST ...|   false|    false|    false|        true|\n",
      "|   580632|    20725|       2|2011-12-05 12:16:00|     1.65|   16360.0|United Kingdom|LUNCH BAG RED RET...|    true|    false|    false|       false|\n",
      "|   580632|    23208|       2|2011-12-05 12:16:00|     1.65|   16360.0|United Kingdom|LUNCH BAG VINTAGE...|    true|    false|    false|       false|\n",
      "|   580636|    22472|       8|2011-12-05 12:33:00|     1.95|   16746.0|United Kingdom|TV DINNER TRAY DO...|   false|     true|    false|       false|\n",
      "|   580636|    22474|       8|2011-12-05 12:33:00|     1.95|   16746.0|United Kingdom|SPACEBOY TV DINNE...|   false|     true|    false|       false|\n",
      "|   580639|    20726|       1|2011-12-05 12:46:00|     1.65|   17254.0|United Kingdom|  LUNCH BAG WOODLAND|    true|    false|    false|       false|\n",
      "|   580639|    23209|       2|2011-12-05 12:46:00|     1.65|   17254.0|United Kingdom|LUNCH BAG VINTAGE...|    true|    false|    false|       false|\n",
      "|   580639|    22382|       1|2011-12-05 12:46:00|     1.65|   17254.0|United Kingdom|LUNCH BAG SPACEBO...|    true|    false|    false|       false|\n",
      "|   580639|    20727|       1|2011-12-05 12:46:00|     1.65|   17254.0|United Kingdom|LUNCH BAG  BLACK ...|    true|    false|    false|       false|\n",
      "|   580647|    21558|       1|2011-12-05 13:14:00|     2.55|   14083.0|United Kingdom|SKULL LUNCH BOX W...|    true|    false|    false|       false|\n",
      "|   580647|    22474|       1|2011-12-05 13:14:00|     1.95|   14083.0|United Kingdom|SPACEBOY TV DINNE...|   false|     true|    false|       false|\n",
      "|   580656|   72800E|      12|2011-12-05 13:40:00|     0.79|   15621.0|United Kingdom|4 IVORY DINNER CA...|   false|     true|    false|       false|\n",
      "|   580656|   72800C|      12|2011-12-05 13:40:00|     0.79|   15621.0|United Kingdom|4 PINK DINNER CAN...|   false|     true|    false|       false|\n",
      "+---------+---------+--------+-------------------+---------+----------+--------------+--------------------+--------+---------+---------+------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.where((col(\"is_Lunch\") == \"True\") | (col(\"is_dinner\") == \"True\")| (col(\"is_supper\") == \"True\")| (col(\"is_breakfast\") == \"True\")).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Output frequencies for each Boolean column you have added in 4.1\n",
    "Note: make sure you take care of the null values in the description field. The output combinations should\n",
    "be either true or false .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|is_Lunch| count|\n",
      "+--------+------+\n",
      "|    true| 18525|\n",
      "|   false|523384|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupBy(\"is_Lunch\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|is_dinner| count|\n",
      "+---------+------+\n",
      "|     true|  1746|\n",
      "|    false|540163|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupBy(\"is_dinner\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|is_supper| count|\n",
      "+---------+------+\n",
      "|    false|541909|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupBy(\"is_supper\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|is_breakfast| count|\n",
      "+------------+------+\n",
      "|        true|  1171|\n",
      "|       false|540738|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.groupBy(\"is_breakfast\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
